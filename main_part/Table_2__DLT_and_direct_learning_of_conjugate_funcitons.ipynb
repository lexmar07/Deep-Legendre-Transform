{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lexmar07/Deep-Legendre-Transform/blob/main/main_part/Table_2__DLT_and_direct_learning_of_conjugate_funcitons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ6rYWYZWwcq"
      },
      "source": [
        "\n",
        "###  Comparing Different NN Architectures\n",
        "\n",
        "####  Comparison with Direct Learning (When Dual is Known)\n",
        "\n",
        "To validate our Deep Legendre Transform (DLT) approach, we compare it to *direct learning* of the convex conjugate in cases where the analytical form of \\$f^\\*\\$ is known.\n",
        "\n",
        "We benchmark DLT against direct learning across multiple convex functions and input dimensions.\n",
        "\n",
        "####  Benchmark Setup\n",
        "\n",
        "We compare two methods:\n",
        "\n",
        "* **DLT (implicit)**: Train $g_\\theta$ such that\n",
        "  $g_\\theta(\\nabla f(x)) \\approx \\langle x, \\nabla f(x) \\rangle - f(x)$\n",
        "* **Direct**: Train $h_\\theta$ to approximate $f^*$ directly,\n",
        "  $h_\\theta(y) \\approx f^*(y)$\n",
        "  Only possible when $f^*$ is known.\n",
        "\n",
        "> Direct learning serves as a \"gold standard\" — but only works when \\$f^\\*\\$ has a closed-form expression.\n",
        "\n",
        "We use the same neural architectures across both methods:\n",
        "\n",
        "* **MLP**: 2 hidden layers, 128 ReLU units\n",
        "* **MLP\\_ICNN**: convex MLP with 2 layers, 128 units\n",
        "* **ResNet**: 2 residual blocks, 128 units\n",
        "* **ICNN**: Input-convex NN with skip connections (Amos et al. 2017), 2×128 layers\n",
        "\n",
        "Optimization:\n",
        "\n",
        "* Adam optimizer, LR = \\$10^{-3}\\$, batch size = 128*d\n",
        "* Early stop when \\$L^2\\_2\\$ error < \\$10^{-6}\\$ or after 50k iterations\n",
        "\n",
        "####  Sampling Strategy\n",
        "\n",
        "We carefully match sampling between primal and dual spaces via the gradient map \\$\\nabla f(x)\\$.\n",
        "\n",
        "* **Quadratic**:\n",
        "  $f(x) = \\frac{1}{2} \\|x\\|^2 \\quad\\Rightarrow\\quad \\nabla f(x) = x,\\quad f^*(y) = \\frac{1}{2} \\|y\\|^2$\n",
        "  Sample \\$x \\sim \\mathcal{N}(0, I)\\$ ⇒ \\$y = x\\$\n",
        "\n",
        "* **Neg. Log**:\n",
        "  $f(x) = -\\sum_{i=1}^d \\log(x_i) \\quad\\Rightarrow\\quad \\nabla f(x) = -\\frac{1}{x_i},\\quad f^*(y) = -\\sum \\log(-y_i) - d$\n",
        "  Sample \\$x\\$ in $\\[0.1, 10]^d\\$ ⇒ \\$y \\in \\[-10, -0.1]^d\\$\n",
        "\n",
        "* **Neg. Entropy**:\n",
        "  $f(x) = \\sum x_i \\log x_i \\quad\\Rightarrow\\quad \\nabla f(x) = \\log x_i + 1,\\quad f^*(y) = \\sum \\exp(y_i - 1)$\n",
        "  Sample \\$x\\$ in log-space ⇒ \\$y \\in \\[-1.3, 3.3]^d\\$\n",
        "\n",
        "#### Results and Analysis\n",
        "\n",
        "We test dimensions \\$d \\in {2, 5, 10, 20}\\$ for:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{Quadratic:} \\quad & f(x) = \\frac{\\|x\\|^2}{2}, \\quad f^*(y) = \\frac{\\|y\\|^2}{2} \\\\\n",
        "\\text{Neg. Log:} \\quad & f(x) = -\\sum \\log(x_i), \\quad f^*(y) = -\\sum \\log(-y_i) - d \\\\\n",
        "\\text{Neg. Entropy:} \\quad & f(x) = \\sum x_i \\log x_i, \\quad f^*(y) = \\sum \\exp(y_i - 1)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZOqpTlOIQJh",
        "outputId": "349b4f1b-f792-47fb-8d99-82058ae7640b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================================================================\n",
            "Quadratic benchmark\n",
            "==============================================================================\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [################....]  80.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [################....]  80.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [############........]  60.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [############........]  60.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [############........]  60.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#######.............]  35.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 1.53e-05  L2expl 1.35e-05  ratio 1.24 σ=0.49\n",
            "MLP_ICNN  L2impl 5.41e-01  L2expl 5.98e-01  ratio 0.91 σ=0.25\n",
            "ResNet    L2impl 9.10e-06  L2expl 1.19e-05  ratio 0.87 σ=0.40\n",
            "ICNN      L2impl 9.62e-04  L2expl 8.56e-04  ratio 1.24 σ=0.57\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 4.57e-04  L2expl 4.48e-04  ratio 1.07 σ=0.38\n",
            "MLP_ICNN  L2impl 3.27e-01  L2expl 3.28e-01  ratio 1.00 σ=0.04\n",
            "ResNet    L2impl 2.10e-04  L2expl 2.35e-04  ratio 0.96 σ=0.26\n",
            "ICNN      L2impl 2.92e-03  L2expl 2.76e-03  ratio 1.09 σ=0.28\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##################..]  90.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 6.37e-03  L2expl 6.12e-03  ratio 1.05 σ=0.19\n",
            "MLP_ICNN  L2impl 4.82e-01  L2expl 4.86e-01  ratio 0.99 σ=0.02\n",
            "ResNet    L2impl 2.34e-03  L2expl 2.28e-03  ratio 1.03 σ=0.07\n",
            "ICNN      L2impl 1.12e-02  L2expl 1.14e-02  ratio 0.99 σ=0.13\n",
            "\n",
            "==============================================================================\n",
            "Neg.\\ Log benchmark\n",
            "==============================================================================\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##################..]  90.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [############........]  60.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 6.70e-05  L2expl 6.91e-05  ratio 1.16 σ=0.66\n",
            "MLP_ICNN  L2impl 5.59e-01  L2expl 5.30e-01  ratio 1.07 σ=0.18\n",
            "ResNet    L2impl 1.64e-05  L2expl 1.24e-05  ratio 1.44 σ=0.53\n",
            "ICNN      L2impl 3.74e-04  L2expl 4.72e-04  ratio 0.83 σ=0.20\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##################..]  90.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 2.06e-03  L2expl 1.79e-03  ratio 1.17 σ=0.20\n",
            "MLP_ICNN  L2impl 1.17e+00  L2expl 1.23e+00  ratio 0.97 σ=0.12\n",
            "ResNet    L2impl 9.04e-04  L2expl 8.50e-04  ratio 1.09 σ=0.33\n",
            "ICNN      L2impl 2.16e-03  L2expl 2.23e-03  ratio 1.08 σ=0.55\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [################....]  80.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##################..]  90.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [########............]  40.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##########..........]  50.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [############........]  60.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#########...........]  45.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#########...........]  45.0%\n",
            "MLP       L2impl 1.01e-02  L2expl 9.56e-03  ratio 1.08 σ=0.21\n",
            "MLP_ICNN  L2impl 3.01e+00  L2expl 3.00e+00  ratio 1.00 σ=0.03\n",
            "ResNet    L2impl 6.02e-03  L2expl 6.25e-03  ratio 1.00 σ=0.19\n",
            "ICNN      L2impl 4.39e+00  L2expl 3.23e+00  ratio 200.54 σ=328.41\n",
            "\n",
            "==============================================================================\n",
            "Neg.\\ Entropy benchmark\n",
            "==============================================================================\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [########............]  40.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [################....]  80.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 5.88e-05  L2expl 4.78e-05  ratio 1.42 σ=0.65\n",
            "MLP_ICNN  L2impl 9.69e-03  L2expl 1.24e-02  ratio 0.97 σ=0.64\n",
            "ResNet    L2impl 5.34e-05  L2expl 4.71e-05  ratio 1.23 σ=0.62\n",
            "ICNN      L2impl 2.88e-04  L2expl 2.89e-04  ratio 1.05 σ=0.25\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 3.29e-03  L2expl 3.61e-03  ratio 0.93 σ=0.22\n",
            "MLP_ICNN  L2impl 6.34e-02  L2expl 6.15e-02  ratio 1.04 σ=0.08\n",
            "ResNet    L2impl 1.99e-03  L2expl 1.90e-03  ratio 1.04 σ=0.22\n",
            "ICNN      L2impl 9.50e-04  L2expl 9.55e-04  ratio 1.08 σ=0.47\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 2.71e-02  L2expl 2.46e-02  ratio 1.11 σ=0.12\n",
            "MLP_ICNN  L2impl 2.58e-01  L2expl 2.55e-01  ratio 1.01 σ=0.07\n",
            "ResNet    L2impl 1.81e-02  L2expl 1.76e-02  ratio 1.03 σ=0.24\n",
            "ICNN      L2impl 2.76e-03  L2expl 2.87e-03  ratio 0.97 σ=0.17\n",
            "LaTeX saved → results/quadratic_table.tex\n",
            "LaTeX saved → results/neg_log_table.tex\n",
            "LaTeX saved → results/neg_entropy_table.tex\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# benchmark.py – implicit vs explicit convex-conjugate learning\n",
        "# ν-sampling • staircase LR • per-model activations (relu|gelu|softplus)\n",
        "# batch size: \"scale\" (d×64) or constant • repeats with σ\n",
        "# prints mean L2 errors and saves LaTeX tables with σ column\n",
        "# --------------------------------------------------------------------\n",
        "from __future__ import annotations\n",
        "import time, os, sys, argparse\n",
        "from functools import partial\n",
        "from typing import Sequence, Callable, Dict\n",
        "import jax, jax.numpy as jnp, optax\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "from jax import random\n",
        "import numpy as np\n",
        "\n",
        "# ═════════ 1. convex test functions ═════════════════════════════════\n",
        "f_quad,  grad_quad  = lambda x:0.5*jnp.sum(x**2,-1),      lambda x:x\n",
        "fst_quad            = lambda y:0.5*jnp.sum(y**2,-1)\n",
        "\n",
        "f_nlog,  grad_nlog  = lambda x:-jnp.sum(jnp.log(x),-1),   lambda x:-1./x\n",
        "fst_nlog            = lambda y:-jnp.sum(jnp.log(-y),-1)-y.shape[-1]\n",
        "\n",
        "f_nent,  grad_nent  = lambda x:jnp.sum(x*jnp.log(x),-1),  lambda x:jnp.log(x)+1\n",
        "fst_nent            = lambda y:jnp.sum(jnp.exp(y-1.),-1)\n",
        "\n",
        "def _u(rng, sh, lo, hi):\n",
        "    return random.uniform(rng, sh, minval=lo, maxval=hi, dtype=jnp.float32)\n",
        "\n",
        "FUNCTIONS = {\n",
        "    \"quadratic\":   (f_quad, grad_quad, fst_quad,\n",
        "                    lambda k,s: random.normal(k, s, jnp.float32)),\n",
        "    \"neg_log\":     (f_nlog, grad_nlog, fst_nlog,\n",
        "                    lambda k,s: jnp.exp(_u(k, s, -2.3, 2.3))),\n",
        "    \"neg_entropy\": (f_nent, grad_nent, fst_nent,\n",
        "                    lambda k,s: jnp.exp(_u(k, s, -2.3, 2.3))),\n",
        "}\n",
        "FUNCPRINT = {\"quadratic\":\"Quadratic\",\n",
        "             \"neg_log\":\"Neg.\\ Log\",\n",
        "             \"neg_entropy\":\"Neg.\\ Entropy\"}\n",
        "\n",
        "# ═════════ 2. activation helper (relu | gelu | softplus) ════════════\n",
        "def _act(name:str)->Callable:\n",
        "    n=name.lower()\n",
        "    if n==\"relu\":     return nn.relu\n",
        "    if n==\"gelu\":     return jax.nn.gelu\n",
        "    if n==\"softplus\": return jax.nn.softplus\n",
        "    raise ValueError(f\"unknown activation {name}\")\n",
        "\n",
        "# ═════════ 3. model zoo (activation pluggable) ═════════════════════=\n",
        "class DensePos(nn.Module):\n",
        "    features:int; use_bias:bool=True\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        W=nn.softplus(self.param(\"raw_W\",nn.initializers.lecun_normal(),\n",
        "                                 (x.shape[-1],self.features)))\n",
        "        y=x@W\n",
        "        if self.use_bias:\n",
        "            y+=self.param(\"b\",nn.initializers.zeros,(self.features,))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        for h in self.hidden: x=self.act(nn.Dense(h)(x))\n",
        "        return jnp.squeeze(nn.Dense(1)(x),-1)\n",
        "\n",
        "class MLP_ICNN(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        z=x\n",
        "        for h in self.hidden: z=self.act(DensePos(h)(z))\n",
        "        out=DensePos(1,use_bias=False)(z)+nn.Dense(1,use_bias=False)(x)\n",
        "        return jnp.squeeze(out,-1)\n",
        "\n",
        "class ICNN(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        z=jnp.zeros((x.shape[0],1))\n",
        "        for h in self.hidden:\n",
        "            z=self.act(DensePos(h)(z)+nn.Dense(h)(x))\n",
        "        out=DensePos(1,use_bias=False)(z)+nn.Dense(1,use_bias=False)(x)\n",
        "        return jnp.squeeze(out,-1)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    f:int; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        y=self.act(nn.Dense(self.f)(x)); y=nn.Dense(self.f)(y)\n",
        "        if x.shape[-1]!=self.f: x=nn.Dense(self.f,use_bias=False)(x)\n",
        "        return self.act(x+y)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        for h in self.hidden: x=ResBlock(h,act=self.act)(x)\n",
        "        return jnp.squeeze(nn.Dense(1)(x),-1)\n",
        "\n",
        "def parse_hidden(s:str)->tuple[int,...]:\n",
        "    return tuple(int(v) for v in s.split(\",\") if v)\n",
        "\n",
        "# ═════════ 4. optimiser / loss / jit helpers ════════════════════════\n",
        "class State(train_state.TrainState): ...\n",
        "def schedule(lr:float): return optax.exponential_decay(lr,20_000,0.5,True)\n",
        "def new_state(rng,model,d,lr):\n",
        "    p=model.init(rng,jnp.zeros((1,d),jnp.float32))[\"params\"]\n",
        "    return State.create(apply_fn=model.apply,params=p,tx=optax.adam(schedule(lr)))\n",
        "\n",
        "loss_impl=lambda p,af,x,f,g:jnp.mean((af({\"params\":p},g(x))-\n",
        "                                      (jnp.sum(x*g(x),-1)-f(x)))**2)\n",
        "loss_expl=lambda p,af,y,fst:jnp.mean((af({\"params\":p},y)-fst(y))**2)\n",
        "\n",
        "@partial(jax.jit, static_argnums=(2,3))\n",
        "def step_impl(st,b,f,g):\n",
        "    l,gr=jax.value_and_grad(loss_impl)(st.params,st.apply_fn,b,f,g)\n",
        "    return st.apply_gradients(grads=gr),l\n",
        "@partial(jax.jit, static_argnums=(2,))\n",
        "def step_expl(st,b,fst):\n",
        "    l,gr=jax.value_and_grad(loss_expl)(st.params,st.apply_fn,b,fst)\n",
        "    return st.apply_gradients(grads=gr),l\n",
        "\n",
        "@partial(jax.jit, static_argnums=(1,3,4))\n",
        "def _ei(p,af,x,f,g): return loss_impl(p,af,x,f,g)\n",
        "def eval_impl(p,af,x,f,g): return float(_ei(p,af,x,f,g))\n",
        "@partial(jax.jit, static_argnums=(1,3))\n",
        "def _ee(p,af,y,fst): return loss_expl(p,af,y,fst)\n",
        "def eval_expl(p,af,y,fst): return float(_ee(p,af,y,fst))\n",
        "\n",
        "# ═════════ 5. early stopping ════════════════════════════════════════\n",
        "class Stopper:\n",
        "    def __init__(self,pat,tol=1e-6):\n",
        "        self.best=float(\"inf\"); self.pat=pat; self.tol=tol\n",
        "        self.cnt=0; self.bp=None\n",
        "    def update(self,loss,p):\n",
        "        loss=float(loss)\n",
        "        if loss+self.tol<self.best:\n",
        "            self.best,self.cnt=loss,0; self.bp=p\n",
        "        else: self.cnt+=1\n",
        "        return self.cnt>=self.pat or self.best<self.tol\n",
        "    def res(self): return self.best,self.bp\n",
        "\n",
        "# ═════════ 6. helper: batch size ════════════════════════════════════\n",
        "def batch_size(d:int,arg:str)->int:\n",
        "    return d*64 if arg==\"scale\" else int(arg)\n",
        "\n",
        "# ═════════ 7. training routine (returns final L2 error) ═════════════\n",
        "def train(model_fn,d,f,g,samp,steps,lr,pat,seed,\n",
        "          implicit,batch,verb=False):\n",
        "    st=new_state(random.PRNGKey(seed),model_fn(),d,lr)\n",
        "    stop=Stopper(pat); stepf=step_impl if implicit else step_expl\n",
        "    tag=\"impl\" if implicit else \"expl\"; bar=max(steps//20,1)\n",
        "    i=0\n",
        "    while i<steps:\n",
        "        mb=samp(random.fold_in(random.PRNGKey(seed+999),i),(batch,d))\n",
        "        st,loss = stepf(st,mb,f,g) if implicit else stepf(st,mb,f)\n",
        "        if stop.update(loss,st.params): break\n",
        "        if verb and i%bar==0:\n",
        "            pct=100*i/steps\n",
        "            print(f\"[{tag}] {i:6d}/{steps} ({pct:5.1f}%) loss {float(loss):.3e}\")\n",
        "        elif (not verb) and i%bar==0:\n",
        "            pct=i/steps; br=int(20*pct)\n",
        "            sys.stdout.write(f\"\\r[{tag}] [{'#'*br}{'.'*(20-br)}] {pct*100:5.1f}%\")\n",
        "            sys.stdout.flush()\n",
        "        i+=1\n",
        "    if not verb: sys.stdout.write(\"\\n\")\n",
        "    _,bp=stop.res()\n",
        "    if implicit:\n",
        "        return eval_impl(bp,st.apply_fn,\n",
        "                         samp(random.PRNGKey(0),(batch,d)),f,g)\n",
        "    else:\n",
        "        return eval_expl(bp,st.apply_fn,\n",
        "                         samp(random.PRNGKey(0),(batch,d)),f)\n",
        "\n",
        "# ═════════ 8. benchmark (L2 means/σ + ratio) ════════════════════════\n",
        "def bench(fn,d,steps,pat,models,runs,batch_arg,verb):\n",
        "    f,g,fst,sampx=FUNCTIONS[fn]; sampy=lambda k,sh:g(sampx(k,sh))\n",
        "    bs=batch_size(d,batch_arg)\n",
        "    rows=[]\n",
        "    for nm,sp in models.items():\n",
        "        l2I,l2E,ratios=[],[],[]\n",
        "        for r in range(runs):\n",
        "            if verb: print(f\"\\n▶ {nm} ({fn},d={d}) run {r+1}/{runs}\")\n",
        "            errI=train(sp[\"make\"],d,f,g,sampx,steps,sp[\"lr\"],pat,\n",
        "                       7000+d*11+r*5,True, bs,verb)\n",
        "            errE=train(sp[\"make\"],d,fst,None,sampy,steps,sp[\"lr\"],pat,\n",
        "                       7100+d*13+r*5,False,bs,verb)\n",
        "            l2I.append(errI); l2E.append(errE)\n",
        "            ratios.append(errI/errE if errE else 1.)\n",
        "        rows.append(dict(model=nm,d=d,\n",
        "                         l2I=float(np.mean(l2I)),\n",
        "                         l2E=float(np.mean(l2E)),\n",
        "                         ratio_mean=float(np.mean(ratios)),\n",
        "                         ratio_sd=float(np.std(ratios))))\n",
        "    return rows\n",
        "\n",
        "# ═════════ 9. LaTeX helper (σ only) ═════════════════════════════════\n",
        "def tex_tables(res:Dict[str,list],dims)->Dict[str,str]:\n",
        "    out={}\n",
        "    for fn,rows in res.items():\n",
        "        tex=[\"\\\\begin{table}[h]\",\"\\\\centering\",\n",
        "             f\"\\\\caption{{Results for {FUNCPRINT[fn]}}}\",\n",
        "             \"\\\\begin{tabular}{cc|cc}\",\n",
        "             \"\\\\toprule\",\n",
        "             \"$d$ & Model & $\\\\mathbb E[\\\\rho]$ & $\\\\sigma(\\\\rho)$ \\\\\\\\ \\\\midrule\"]\n",
        "        for d in dims:\n",
        "            dr=[r for r in rows if r[\"d\"]==d]\n",
        "            if not dr: continue\n",
        "            tex.append(f\"\\\\multirow{{{len(dr)}}}{{*}}{{{d}}}\")\n",
        "            for i,r in enumerate(dr):\n",
        "                line=\" & \".join([r[\"model\"],\n",
        "                                 f\"{r['ratio_mean']:.2f}\",\n",
        "                                 f\"{r['ratio_sd']:.2f}\"])+\"\\\\\\\\\"\n",
        "                tex.append((\" \" if i else \"\")+line)\n",
        "            if d!=dims[-1]: tex.append(\"\\\\cmidrule{2-4}\")\n",
        "        tex+=[\"\\\\bottomrule\",\"\\\\end{tabular}\",\"\\\\end{table}\"]\n",
        "        out[fn]=\"\\n\".join(tex)\n",
        "    return out\n",
        "\n",
        "# ═════════ 10. CLI & main ═══════════════════════════════════════════\n",
        "def build_parser():\n",
        "    P=argparse.ArgumentParser()\n",
        "    P.add_argument(\"--steps\",type=int,default=50000)\n",
        "    P.add_argument(\"--patience\",type=int,default=10000)\n",
        "    P.add_argument(\"--lr\",type=float,default=1e-3)\n",
        "    P.add_argument(\"--runs\",type=int,default=10)\n",
        "    P.add_argument(\"--batch\",default=\"scale\")\n",
        "    P.add_argument(\"--dims\",nargs=\"+\",type=int,default=[2,5,10])\n",
        "    P.add_argument(\"--verbose\",action=\"store_true\")\n",
        "    # hidden sizes\n",
        "    P.add_argument(\"--mlp_hidden\",default=\"128,128\")\n",
        "    P.add_argument(\"--mlp_icnn_hidden\",default=\"128,128\")\n",
        "    P.add_argument(\"--resnet_hidden\",default=\"128,128\")\n",
        "    P.add_argument(\"--icnn_hidden\",default=\"128,128\")\n",
        "    # learning-rates\n",
        "    P.add_argument(\"--mlp_lr\",type=float);  P.add_argument(\"--mlp_icnn_lr\",type=float)\n",
        "    P.add_argument(\"--resnet_lr\",type=float); P.add_argument(\"--icnn_lr\",type=float)\n",
        "    # activations\n",
        "    # P.add_argument(\"--mlp_act\",default=\"relu\")\n",
        "    # P.add_argument(\"--mlp_icnn_act\",default=\"relu\")\n",
        "    # P.add_argument(\"--resnet_act\",default=\"relu\")\n",
        "    # P.add_argument(\"--icnn_act\",default=\"relu\")\n",
        "    P.add_argument(\"--mlp_act\",default=\"relu\")\n",
        "    P.add_argument(\"--mlp_icnn_act\",default=\"softplus\")\n",
        "    P.add_argument(\"--resnet_act\",default=\"relu\")\n",
        "    P.add_argument(\"--icnn_act\",default=\"softplus\")\n",
        "    return P\n",
        "\n",
        "def main(argv=None):\n",
        "    args,_=build_parser().parse_known_args(argv or sys.argv[1:])\n",
        "    os.makedirs(\"results\",exist_ok=True)\n",
        "    base_lr=args.lr\n",
        "    models={\n",
        "        \"MLP\":{\"make\":lambda:MLP(parse_hidden(args.mlp_hidden),\n",
        "                                 act=_act(args.mlp_act)),\n",
        "               \"lr\":args.mlp_lr or base_lr},\n",
        "        \"MLP_ICNN\":{\"make\":lambda:MLP_ICNN(parse_hidden(args.mlp_icnn_hidden),\n",
        "                                           act=_act(args.mlp_icnn_act)),\n",
        "               \"lr\":args.mlp_icnn_lr or base_lr*3},\n",
        "        \"ResNet\":{\"make\":lambda:ResNet(parse_hidden(args.resnet_hidden),\n",
        "                                       act=_act(args.resnet_act)),\n",
        "               \"lr\":args.resnet_lr or base_lr},\n",
        "        \"ICNN\":{\"make\":lambda:ICNN(parse_hidden(args.icnn_hidden),\n",
        "                                   act=_act(args.icnn_act)),\n",
        "               \"lr\":args.icnn_lr or base_lr*3},\n",
        "    }\n",
        "\n",
        "    all_res={}\n",
        "    for fn in FUNCTIONS:\n",
        "        print(\"\\n\"+\"=\"*78+f\"\\n{FUNCPRINT[fn]} benchmark\\n\"+\"=\"*78)\n",
        "        all_res[fn]=[]\n",
        "        for d in args.dims:\n",
        "            rows=bench(fn,d,args.steps,args.patience,\n",
        "                       models,args.runs,args.batch,args.verbose)\n",
        "            all_res[fn].extend(rows)\n",
        "            for r in rows:\n",
        "                print(f\"{r['model']:<10}\"\n",
        "                      f\"L2impl {r['l2I']:.2e}  L2expl {r['l2E']:.2e}  \"\n",
        "                      f\"ratio {r['ratio_mean']:.2f} σ={r['ratio_sd']:.2f}\")\n",
        "    # ➜ LaTeX\n",
        "    tables=tex_tables(all_res,args.dims)\n",
        "    for fn,tex in tables.items():\n",
        "        fname=f\"results/{fn}_table.tex\"\n",
        "        with open(fname,\"w\") as f: f.write(tex)\n",
        "        print(f\"LaTeX saved → {fname}\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XQIvaEks-1yc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLpmi0fkd-x-",
        "outputId": "28aefc13-33f1-4737-a7ca-9ebdb27bb743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================================================================\n",
            "Quadratic benchmark\n",
            "==============================================================================\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [################....]  80.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [############........]  60.0%\n",
            "[impl] [###########.........]  55.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###########.........]  55.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###########.........]  55.0%\n",
            "[impl] [#######.............]  35.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 1.70e-05  L2dir 1.30e-05  time 69.5/78.5s  ρ 1.42 σ=0.55\n",
            "MLP_ICNN  L2impl 4.44e-01  L2dir 5.03e-01  time 66.1/62.7s  ρ 1.54 σ=2.22\n",
            "ResNet    L2impl 2.24e-05  L2dir 1.03e-05  time 75.5/94.3s  ρ 2.51 σ=2.56\n",
            "ICNN      L2impl 8.26e-04  L2dir 8.79e-04  time 91.0/91.2s  ρ 1.04 σ=0.62\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 4.19e-04  L2dir 4.13e-04  time 81.0/81.3s  ρ 1.07 σ=0.40\n",
            "MLP_ICNN  L2impl 3.23e-01  L2dir 3.18e-01  time 82.8/83.4s  ρ 1.02 σ=0.08\n",
            "ResNet    L2impl 2.03e-04  L2dir 2.05e-04  time 93.3/93.3s  ρ 1.02 σ=0.25\n",
            "ICNN      L2impl 1.82e-03  L2dir 1.80e-03  time 89.9/89.8s  ρ 1.02 σ=0.22\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [################....]  80.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 5.68e-03  L2dir 5.64e-03  time 81.1/77.9s  ρ 1.02 σ=0.19\n",
            "MLP_ICNN  L2impl 4.74e-01  L2dir 4.81e-01  time 83.6/83.6s  ρ 0.99 σ=0.02\n",
            "ResNet    L2impl 2.03e-03  L2dir 2.06e-03  time 92.6/92.5s  ρ 1.00 σ=0.17\n",
            "ICNN      L2impl 6.45e-03  L2dir 6.18e-03  time 89.7/89.6s  ρ 1.06 σ=0.15\n",
            "\n",
            "==============================================================================\n",
            "Neg.\\ Log benchmark\n",
            "==============================================================================\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 7.32e-05  L2dir 6.08e-05  time 89.7/94.2s  ρ 1.20 σ=0.62\n",
            "MLP_ICNN  L2impl 5.33e-01  L2dir 5.20e-01  time 77.1/83.1s  ρ 1.06 σ=0.28\n",
            "ResNet    L2impl 1.42e-05  L2dir 1.37e-05  time 99.3/103.8s  ρ 1.23 σ=0.68\n",
            "ICNN      L2impl 2.76e-04  L2dir 3.19e-04  time 96.6/101.1s  ρ 0.93 σ=0.25\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##################..]  90.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [##########..........]  50.0%\n",
            "[expl] [##################..]  90.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##################..]  90.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 1.68e-03  L2dir 1.47e-03  time 90.6/95.2s  ρ 1.17 σ=0.32\n",
            "MLP_ICNN  L2impl 1.24e+00  L2dir 1.22e+00  time 83.7/88.0s  ρ 1.04 σ=0.25\n",
            "ResNet    L2impl 6.24e-04  L2dir 6.74e-04  time 100.2/104.8s  ρ 0.95 σ=0.24\n",
            "ICNN      L2impl 1.64e-03  L2dir 1.73e-03  time 96.9/101.5s  ρ 1.06 σ=0.56\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#################...]  85.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#############.......]  65.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##################..]  90.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [############........]  60.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [############........]  60.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###############.....]  75.0%\n",
            "[expl] [#################...]  85.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [########............]  40.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##########..........]  50.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##########..........]  50.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#########...........]  45.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [#########...........]  45.0%\n",
            "MLP       L2impl 8.36e-03  L2dir 8.31e-03  time 89.8/95.1s  ρ 1.04 σ=0.18\n",
            "MLP_ICNN  L2impl 3.06e+00  L2dir 3.04e+00  time 78.6/79.9s  ρ 1.01 σ=0.05\n",
            "ResNet    L2impl 4.85e-03  L2dir 4.44e-03  time 100.1/104.7s  ρ 1.10 σ=0.18\n",
            "ICNN      L2impl 2.56e+00  L2dir 2.12e+00  time 82.3/81.6s  ρ 201.30 σ=403.37\n",
            "\n",
            "==============================================================================\n",
            "Neg.\\ Entropy benchmark\n",
            "==============================================================================\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###############.....]  75.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [#############.......]  65.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 6.09e-05  L2dir 4.63e-05  time 89.8/96.1s  ρ 1.39 σ=0.33\n",
            "MLP_ICNN  L2impl 1.19e-02  L2dir 1.18e-02  time 90.4/99.2s  ρ 1.22 σ=0.78\n",
            "ResNet    L2impl 5.40e-05  L2dir 5.00e-05  time 95.8/102.3s  ρ 1.27 σ=0.71\n",
            "ICNN      L2impl 2.22e-04  L2dir 2.02e-04  time 96.2/105.1s  ρ 1.15 σ=0.26\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [##############......]  70.0%\n",
            "[expl] [##############......]  70.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 3.41e-03  L2dir 3.29e-03  time 88.2/96.6s  ρ 1.07 σ=0.24\n",
            "MLP_ICNN  L2impl 3.55e-02  L2dir 3.63e-02  time 90.8/98.7s  ρ 0.99 σ=0.12\n",
            "ResNet    L2impl 1.63e-03  L2dir 1.79e-03  time 99.8/108.4s  ρ 0.95 σ=0.23\n",
            "ICNN      L2impl 7.70e-04  L2dir 6.91e-04  time 96.1/105.7s  ρ 1.27 σ=0.61\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "[impl] [###################.]  95.0%\n",
            "[expl] [###################.]  95.0%\n",
            "MLP       L2impl 2.25e-02  L2dir 2.03e-02  time 90.1/99.2s  ρ 1.12 σ=0.14\n",
            "MLP_ICNN  L2impl 7.85e-02  L2dir 7.93e-02  time 90.7/99.4s  ρ 0.99 σ=0.08\n",
            "ResNet    L2impl 1.53e-02  L2dir 1.46e-02  time 100.0/108.3s  ρ 1.04 σ=0.22\n",
            "ICNN      L2impl 2.06e-03  L2dir 2.06e-03  time 97.0/105.4s  ρ 1.01 σ=0.21\n",
            "\n",
            "Combined LaTeX table (also saved to results/combined_table.tex):\n",
            "\n",
            "\\begin{table}[h]\n",
            "  \\centering\n",
            "  \\caption{Benchmark results comparing implicit DLT against direct learning with known duals}\n",
            "  \\label{tab:combined_benchmark}\n",
            "  \\begin{tabular}{ccc|cc|cc|cc}\n",
            "    \\toprule\n",
            "    \\multirow{2}{*}{Function} & \\multirow{2}{*}{$d$} & \\multirow{2}{*}{Model} & \\multicolumn{2}{c|}{$L^2$ Error} & \\multicolumn{2}{c|}{Time (s)} & \\multicolumn{2}{c}{Ratio} \\\\\n",
            "    & & & Impl. & Dir. & Impl. & Dir. & $\\mu$ & $\\sigma$ \\\\\n",
            "    \\midrule\n",
            "\\multirow{12}{*}{Quadratic} & \\multirow{4}{*}{2} & MLP & 1.70e-05 & 1.30e-05 & 69.5 & 78.5 & 1.42 & 0.55 \\\\\n",
            "  &   & MLP_ICNN & 4.44e-01 & 5.03e-01 & 66.1 & 62.7 & 1.54 & 2.22 \\\\\n",
            "  &   & ResNet & 2.24e-05 & 1.03e-05 & 75.5 & 94.3 & 2.51 & 2.56 \\\\\n",
            "  &   & ICNN & 8.26e-04 & 8.79e-04 & 91.0 & 91.2 & 1.04 & 0.62 \\\\\n",
            "    \\cmidrule{2-9}\n",
            "  & \\multirow{4}{*}{5} & MLP & 4.19e-04 & 4.13e-04 & 81.0 & 81.3 & 1.07 & 0.40 \\\\\n",
            "  &   & MLP_ICNN & 3.23e-01 & 3.18e-01 & 82.8 & 83.4 & 1.02 & 0.08 \\\\\n",
            "  &   & ResNet & 2.03e-04 & 2.05e-04 & 93.3 & 93.3 & 1.02 & 0.25 \\\\\n",
            "  &   & ICNN & 1.82e-03 & 1.80e-03 & 89.9 & 89.8 & 1.02 & 0.22 \\\\\n",
            "    \\cmidrule{2-9}\n",
            "  & \\multirow{4}{*}{10} & MLP & 5.68e-03 & 5.64e-03 & 81.1 & 77.9 & 1.02 & 0.19 \\\\\n",
            "  &   & MLP_ICNN & 4.74e-01 & 4.81e-01 & 83.6 & 83.6 & 0.99 & 0.02 \\\\\n",
            "  &   & ResNet & 2.03e-03 & 2.06e-03 & 92.6 & 92.5 & 1.00 & 0.17 \\\\\n",
            "  &   & ICNN & 6.45e-03 & 6.18e-03 & 89.7 & 89.6 & 1.06 & 0.15 \\\\\n",
            "    \\midrule\n",
            "\\multirow{12}{*}{Neg.\\ Log} & \\multirow{4}{*}{2} & MLP & 7.32e-05 & 6.08e-05 & 89.7 & 94.2 & 1.20 & 0.62 \\\\\n",
            "  &   & MLP_ICNN & 5.33e-01 & 5.20e-01 & 77.1 & 83.1 & 1.06 & 0.28 \\\\\n",
            "  &   & ResNet & 1.42e-05 & 1.37e-05 & 99.3 & 103.8 & 1.23 & 0.68 \\\\\n",
            "  &   & ICNN & 2.76e-04 & 3.19e-04 & 96.6 & 101.1 & 0.93 & 0.25 \\\\\n",
            "    \\cmidrule{2-9}\n",
            "  & \\multirow{4}{*}{5} & MLP & 1.68e-03 & 1.47e-03 & 90.6 & 95.2 & 1.17 & 0.32 \\\\\n",
            "  &   & MLP_ICNN & 1.24e+00 & 1.22e+00 & 83.7 & 88.0 & 1.04 & 0.25 \\\\\n",
            "  &   & ResNet & 6.24e-04 & 6.74e-04 & 100.2 & 104.8 & 0.95 & 0.24 \\\\\n",
            "  &   & ICNN & 1.64e-03 & 1.73e-03 & 96.9 & 101.5 & 1.06 & 0.56 \\\\\n",
            "    \\cmidrule{2-9}\n",
            "  & \\multirow{4}{*}{10} & MLP & 8.36e-03 & 8.31e-03 & 89.8 & 95.1 & 1.04 & 0.18 \\\\\n",
            "  &   & MLP_ICNN & 3.06e+00 & 3.04e+00 & 78.6 & 79.9 & 1.01 & 0.05 \\\\\n",
            "  &   & ResNet & 4.85e-03 & 4.44e-03 & 100.1 & 104.7 & 1.10 & 0.18 \\\\\n",
            "  &   & ICNN & 2.56e+00 & 2.12e+00 & 82.3 & 81.6 & 201.30 & 403.37 \\\\\n",
            "    \\midrule\n",
            "\\multirow{12}{*}{Neg.\\ Entropy} & \\multirow{4}{*}{2} & MLP & 6.09e-05 & 4.63e-05 & 89.8 & 96.1 & 1.39 & 0.33 \\\\\n",
            "  &   & MLP_ICNN & 1.19e-02 & 1.18e-02 & 90.4 & 99.2 & 1.22 & 0.78 \\\\\n",
            "  &   & ResNet & 5.40e-05 & 5.00e-05 & 95.8 & 102.3 & 1.27 & 0.71 \\\\\n",
            "  &   & ICNN & 2.22e-04 & 2.02e-04 & 96.2 & 105.1 & 1.15 & 0.26 \\\\\n",
            "    \\cmidrule{2-9}\n",
            "  & \\multirow{4}{*}{5} & MLP & 3.41e-03 & 3.29e-03 & 88.2 & 96.6 & 1.07 & 0.24 \\\\\n",
            "  &   & MLP_ICNN & 3.55e-02 & 3.63e-02 & 90.8 & 98.7 & 0.99 & 0.12 \\\\\n",
            "  &   & ResNet & 1.63e-03 & 1.79e-03 & 99.8 & 108.4 & 0.95 & 0.23 \\\\\n",
            "  &   & ICNN & 7.70e-04 & 6.91e-04 & 96.1 & 105.7 & 1.27 & 0.61 \\\\\n",
            "    \\cmidrule{2-9}\n",
            "  & \\multirow{4}{*}{10} & MLP & 2.25e-02 & 2.03e-02 & 90.1 & 99.2 & 1.12 & 0.14 \\\\\n",
            "  &   & MLP_ICNN & 7.85e-02 & 7.93e-02 & 90.7 & 99.4 & 0.99 & 0.08 \\\\\n",
            "  &   & ResNet & 1.53e-02 & 1.46e-02 & 100.0 & 108.3 & 1.04 & 0.22 \\\\\n",
            "  &   & ICNN & 2.06e-03 & 2.06e-03 & 97.0 & 105.4 & 1.01 & 0.21 \\\\\n",
            "    \\bottomrule\n",
            "  \\end{tabular}\n",
            "\\end{table}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# benchmark.py – implicit vs explicit convex-conjugate learning\n",
        "# ν‑sampling • staircase LR • per‑model activations (relu|gelu|softplus)\n",
        "# batch size: \"scale\" (d×64) or constant • repeats with σ\n",
        "# prints rows + one combined LaTeX table\n",
        "# --------------------------------------------------------------------\n",
        "from __future__ import annotations\n",
        "import os, sys, time, argparse\n",
        "from functools import partial\n",
        "from typing import Sequence, Callable, Dict\n",
        "\n",
        "import jax, jax.numpy as jnp, optax\n",
        "from jax import random\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import numpy as np\n",
        "\n",
        "# ═════ 1. convex test functions ═════════════════════════════════════\n",
        "f_quad,  grad_quad  = lambda x: 0.5*jnp.sum(x**2, -1),        lambda x: x\n",
        "fst_quad            = lambda y: 0.5*jnp.sum(y**2, -1)\n",
        "\n",
        "f_nlog,  grad_nlog  = lambda x:-jnp.sum(jnp.log(x), -1),      lambda x:-1./x\n",
        "fst_nlog            = lambda y:-jnp.sum(jnp.log(-y), -1) - y.shape[-1]\n",
        "\n",
        "f_nent,  grad_nent  = lambda x:jnp.sum(x*jnp.log(x), -1),     lambda x:jnp.log(x)+1\n",
        "fst_nent            = lambda y:jnp.sum(jnp.exp(y-1.), -1)\n",
        "\n",
        "def _u(rng, sh, lo, hi):\n",
        "    return random.uniform(rng, shape=sh, minval=lo, maxval=hi,\n",
        "                          dtype=jnp.float32)\n",
        "\n",
        "FUNCTIONS = {\n",
        "    \"quadratic\":   (f_quad, grad_quad, fst_quad,\n",
        "                    lambda k,s: random.normal(k, s, dtype=jnp.float32)),\n",
        "    \"neg_log\":     (f_nlog, grad_nlog, fst_nlog,\n",
        "                    lambda k,s: jnp.exp(_u(k, s, -2.3,  2.3))),\n",
        "    \"neg_entropy\": (f_nent, grad_nent, fst_nent,\n",
        "                    lambda k,s: jnp.exp(_u(k, s, -2.3,  2.3))),\n",
        "}\n",
        "FUNCPRINT = {\"quadratic\": \"Quadratic\",\n",
        "             \"neg_log\":   \"Neg.\\ Log\",\n",
        "             \"neg_entropy\":\"Neg.\\ Entropy\"}\n",
        "\n",
        "# ═════ 2. activations ═══════════════════════════════════════════════\n",
        "def _act(name:str)->Callable:\n",
        "    n=name.lower()\n",
        "    if n==\"relu\":     return nn.relu\n",
        "    if n==\"gelu\":     return jax.nn.gelu\n",
        "    if n==\"softplus\": return jax.nn.softplus\n",
        "    raise ValueError(f\"unknown activation {name}\")\n",
        "\n",
        "# ═════ 3. model zoo ═════════════════════════════════════════════════\n",
        "class DensePos(nn.Module):\n",
        "    features:int; use_bias:bool=True\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        W = nn.softplus(self.param(\"rawW\", nn.initializers.lecun_normal(),\n",
        "                                   (x.shape[-1], self.features)))\n",
        "        y = x @ W\n",
        "        if self.use_bias:\n",
        "            y += self.param(\"b\", nn.initializers.zeros, (self.features,))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        for h in self.hidden: x = self.act(nn.Dense(h)(x))\n",
        "        return jnp.squeeze(nn.Dense(1)(x), -1)\n",
        "\n",
        "class MLP_ICNN(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        z=x\n",
        "        for h in self.hidden: z = self.act(DensePos(h)(z))\n",
        "        out = DensePos(1, use_bias=False)(z) + nn.Dense(1, use_bias=False)(x)\n",
        "        return jnp.squeeze(out, -1)\n",
        "\n",
        "class ICNN(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        z=jnp.zeros((x.shape[0],1))\n",
        "        for h in self.hidden:\n",
        "            z = self.act(DensePos(h)(z) + nn.Dense(h)(x))\n",
        "        out = DensePos(1, use_bias=False)(z) + nn.Dense(1, use_bias=False)(x)\n",
        "        return jnp.squeeze(out, -1)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    f:int; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        y=self.act(nn.Dense(self.f)(x)); y=nn.Dense(self.f)(y)\n",
        "        if x.shape[-1]!=self.f:\n",
        "            x = nn.Dense(self.f, use_bias=False)(x)\n",
        "        return self.act(x+y)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    hidden:Sequence[int]; act:Callable=nn.relu\n",
        "    @nn.compact\n",
        "    def __call__(self,x):\n",
        "        for h in self.hidden: x = ResBlock(h, act=self.act)(x)\n",
        "        return jnp.squeeze(nn.Dense(1)(x), -1)\n",
        "\n",
        "def parse_hidden(s:str)->tuple[int,...]:\n",
        "    return tuple(int(v) for v in s.split(\",\") if v)\n",
        "\n",
        "# ═════ 4. optimiser / losses / jit helpers ═════════════════════════\n",
        "class State(train_state.TrainState): ...\n",
        "\n",
        "def schedule(lr:float):\n",
        "    return optax.exponential_decay(lr, 20_000, 0.5, staircase=True)\n",
        "\n",
        "def new_state(rng, model, d, lr):\n",
        "    params = model.init(rng, jnp.zeros((1, d), jnp.float32))[\"params\"]\n",
        "    return State.create(apply_fn=model.apply, params=params,\n",
        "                        tx=optax.adam(schedule(lr)))\n",
        "\n",
        "loss_impl = lambda p,af,x,f,g: jnp.mean(\n",
        "    (af({\"params\":p}, g(x)) - (jnp.sum(x*g(x), -1) - f(x)))**2)\n",
        "loss_expl = lambda p,af,y,fst: jnp.mean((af({\"params\":p}, y) - fst(y))**2)\n",
        "\n",
        "@partial(jax.jit, static_argnums=(2,3))\n",
        "def step_impl(st,b,f,g):\n",
        "    l,gr = jax.value_and_grad(loss_impl)(st.params, st.apply_fn, b, f, g)\n",
        "    return st.apply_gradients(grads=gr), l\n",
        "\n",
        "@partial(jax.jit, static_argnums=(2,))\n",
        "def step_expl(st,b,fst):\n",
        "    l,gr = jax.value_and_grad(loss_expl)(st.params, st.apply_fn, b, fst)\n",
        "    return st.apply_gradients(grads=gr), l\n",
        "\n",
        "@partial(jax.jit, static_argnums=(1,3,4))\n",
        "def _ei(p,af,x,f,g): return loss_impl(p,af,x,f,g)\n",
        "def eval_impl(p,af,x,f,g): return float(_ei(p,af,x,f,g))\n",
        "\n",
        "@partial(jax.jit, static_argnums=(1,3))\n",
        "def _ee(p,af,y,fst): return loss_expl(p,af,y,fst)\n",
        "def eval_expl(p,af,y,fst): return float(_ee(p,af,y,fst))\n",
        "\n",
        "# ═════ 5. early stopping ═══════════════════════════════════════════\n",
        "class Stopper:\n",
        "    def __init__(self, pat:int, tol:float=1e-6):\n",
        "        self.best=float(\"inf\"); self.pat=pat; self.tol=tol\n",
        "        self.cnt=0; self.bp=None\n",
        "    def update(self, loss, params):\n",
        "        loss=float(loss)\n",
        "        if loss+self.tol < self.best:\n",
        "            self.best, self.cnt = loss, 0; self.bp = params\n",
        "        else:\n",
        "            self.cnt += 1\n",
        "        return self.cnt >= self.pat or self.best < self.tol\n",
        "    def res(self): return self.best, self.bp\n",
        "\n",
        "# ═════ 6. utilities ════════════════════════════════════════════════\n",
        "def batch_size(d:int, arg:str)->int:\n",
        "    return d*64 if arg==\"scale\" else int(arg)\n",
        "\n",
        "# ═════ 7. training routine (returns err & time) ════════════════════\n",
        "def train(model_fn, d, f, g, samp, steps, lr, pat, seed,\n",
        "          implicit:bool, batch:int, verb=False):\n",
        "    st   = new_state(random.PRNGKey(seed), model_fn(), d, lr)\n",
        "    stop = Stopper(pat)\n",
        "    step = step_impl if implicit else step_expl\n",
        "    tag  = \"impl\" if implicit else \"expl\"\n",
        "    bar  = max(steps//20, 1)\n",
        "    t0   = time.perf_counter()\n",
        "\n",
        "    for i in range(steps):\n",
        "        mb = samp(random.fold_in(random.PRNGKey(seed+999), i), (batch, d))\n",
        "        st, loss = step(st, mb, f, g) if implicit else step(st, mb, f)\n",
        "        if stop.update(loss, st.params):\n",
        "            break\n",
        "        if not verb and i%bar==0:\n",
        "            pct = i/steps; br = int(20*pct)\n",
        "            sys.stdout.write(f\"\\r[{tag}] [{'#'*br}{'.'*(20-br)}] {pct*100:5.1f}%\")\n",
        "            sys.stdout.flush()\n",
        "        elif verb and i%bar==0:\n",
        "            print(f\"[{tag}] {i:6d}/{steps} \"\n",
        "                  f\"({100*i/steps:5.1f}%) loss {float(loss):.3e}\")\n",
        "    if not verb:\n",
        "        sys.stdout.write(\"\\n\")\n",
        "\n",
        "    _, bp = stop.res()\n",
        "    rng0  = random.PRNGKey(0)\n",
        "    err = (eval_impl if implicit else eval_expl)(\n",
        "        bp, st.apply_fn,\n",
        "        samp(rng0, (batch, d)),\n",
        "        f, g) if implicit else \\\n",
        "        eval_expl(bp, st.apply_fn, samp(rng0, (batch, d)), f)\n",
        "    return err, time.perf_counter() - t0\n",
        "\n",
        "# ═════ 8. benchmark (means, σ, times) ══════════════════════════════\n",
        "def bench(fn, d, steps, pat, models, runs, batch_arg, verb):\n",
        "    f, g, fst, sampx = FUNCTIONS[fn]\n",
        "    sampy = lambda k, sh: g(sampx(k, sh))\n",
        "    bs = batch_size(d, batch_arg)\n",
        "    rows = []\n",
        "\n",
        "    for nm, sp in models.items():\n",
        "        l2I, l2E, tI, tE, ratios = [], [], [], [], []\n",
        "        for r in range(runs):\n",
        "            if verb: print(f\"\\n▶ {nm} ({fn}, d={d}) run {r+1}/{runs}\")\n",
        "            errI, timeI = train(sp[\"make\"], d, f, g, sampx,\n",
        "                                steps, sp[\"lr\"], pat,\n",
        "                                7000+d*11+r*5, True,  bs, verb)\n",
        "            errE, timeE = train(sp[\"make\"], d, fst, None, sampy,\n",
        "                                steps, sp[\"lr\"], pat,\n",
        "                                7100+d*13+r*5, False, bs, verb)\n",
        "            l2I.append(errI); l2E.append(errE)\n",
        "            tI.append(timeI);  tE.append(timeE)\n",
        "            ratios.append(errI/errE if errE else 1.)\n",
        "        rows.append(dict(model=nm, d=d,\n",
        "                         l2I=float(np.mean(l2I)), l2E=float(np.mean(l2E)),\n",
        "                         tI=float(np.mean(tI)),   tE=float(np.mean(tE)),\n",
        "                         rho_mu=float(np.mean(ratios)),\n",
        "                         rho_sigma=float(np.std(ratios))))\n",
        "    return rows\n",
        "\n",
        "# ═════ 9. combined LaTeX helper ════════════════════════════════════\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 9′.  Combined LaTeX helper  (4 rows per model‑block, keeps Time + σ)\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "def tex_tables(res: Dict[str, list], dims):\n",
        "    fun_order = [\"quadratic\", \"neg_log\", \"neg_entropy\"]\n",
        "    model_order = [\"MLP\", \"MLP_ICNN\", \"ResNet\", \"ICNN\"]\n",
        "\n",
        "    tex = [\n",
        "        \"\\\\begin{table}[h]\",\n",
        "        \"  \\\\centering\",\n",
        "        \"  \\\\caption{Benchmark results comparing implicit DLT against direct learning with known duals}\",\n",
        "        \"  \\\\label{tab:combined_benchmark}\",\n",
        "        \"  \\\\begin{tabular}{ccc|cc|cc|cc}\",\n",
        "        \"    \\\\toprule\",\n",
        "        \"    \\\\multirow{2}{*}{Function} & \\\\multirow{2}{*}{$d$} & \\\\multirow{2}{*}{Model}\"\n",
        "        \" & \\\\multicolumn{2}{c|}{$L^2$ Error} & \\\\multicolumn{2}{c|}{Time (s)} & \\\\multicolumn{2}{c}{Ratio} \\\\\\\\\",\n",
        "        \"    & & & Impl. & Dir. & Impl. & Dir. & $\\\\mu$ & $\\\\sigma$ \\\\\\\\\",\n",
        "        \"    \\\\midrule\"\n",
        "    ]\n",
        "\n",
        "    for fn in fun_order:\n",
        "        rows_fn = sorted(res.get(fn, []),\n",
        "                         key=lambda r: (r[\"d\"], model_order.index(r[\"model\"])))\n",
        "        if not rows_fn:\n",
        "            continue\n",
        "        total_rows_fn = len(rows_fn)\n",
        "        fn_first_row_written = False\n",
        "\n",
        "        for d in dims:\n",
        "            rows_dim = [r for r in rows_fn if r[\"d\"] == d]\n",
        "            if not rows_dim:\n",
        "                continue\n",
        "            rows_dim = sorted(rows_dim,\n",
        "                              key=lambda r: model_order.index(r[\"model\"]))\n",
        "            dim_first_row_written = False\n",
        "\n",
        "            for r in rows_dim:\n",
        "                line_parts = []\n",
        "                # Function column\n",
        "                if not fn_first_row_written:\n",
        "                    line_parts.append(\n",
        "                        f\"\\\\multirow{{{total_rows_fn}}}{{*}}{{{FUNCPRINT[fn]}}}\")\n",
        "                    fn_first_row_written = True\n",
        "                else:\n",
        "                    line_parts.append(\" \")\n",
        "\n",
        "                # Dimension column\n",
        "                if not dim_first_row_written:\n",
        "                    line_parts.append(\n",
        "                        f\"\\\\multirow{{{len(rows_dim)}}}{{*}}{{{d}}}\")\n",
        "                    dim_first_row_written = True\n",
        "                else:\n",
        "                    line_parts.append(\" \")\n",
        "\n",
        "                # Model + metrics\n",
        "                line_parts.extend([\n",
        "                    r[\"model\"],\n",
        "                    f\"{r['l2I']:.2e}\", f\"{r['l2E']:.2e}\",\n",
        "                    f\"{r['tI']:.1f}\",  f\"{r['tE']:.1f}\",\n",
        "                    f\"{r['rho_mu']:.2f}\", f\"{r['rho_sigma']:.2f}\"\n",
        "                ])\n",
        "                tex.append(\" & \".join(line_parts) + \" \\\\\\\\\")\n",
        "            # horizontal line between different d‑blocks\n",
        "            if d != dims[-1]:\n",
        "                tex.append(\"    \\\\cmidrule{2-9}\")\n",
        "        # mid‑rule between functions\n",
        "        if fn != fun_order[-1]:\n",
        "            tex.append(\"    \\\\midrule\")\n",
        "\n",
        "    tex += [\n",
        "        \"    \\\\bottomrule\",\n",
        "        \"  \\\\end{tabular}\",\n",
        "        \"\\\\end{table}\"\n",
        "    ]\n",
        "\n",
        "    table = \"\\n\".join(tex)\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    with open(\"results/combined_table.tex\", \"w\") as f:\n",
        "        f.write(table)\n",
        "    print(\"\\nCombined LaTeX table (also saved to results/combined_table.tex):\\n\")\n",
        "    print(table + \"\\n\")\n",
        "    return table\n",
        "\n",
        "\n",
        "# ═════ 10. CLI & main ═══════════════════════════════════════════════\n",
        "def build_parser():\n",
        "    P = argparse.ArgumentParser()\n",
        "    P.add_argument(\"--steps\", type=int, default=50_000)\n",
        "    P.add_argument(\"--patience\", type=int, default=10_000)\n",
        "    P.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    P.add_argument(\"--runs\", type=int, default=10)\n",
        "    P.add_argument(\"--batch\", default=\"scale\")\n",
        "    P.add_argument(\"--dims\", nargs=\"+\", type=int, default=[2, 5, 10])\n",
        "    P.add_argument(\"--verbose\", action=\"store_true\")\n",
        "    # hidden sizes\n",
        "    P.add_argument(\"--mlp_hidden\", default=\"128,128\")\n",
        "    P.add_argument(\"--mlp_icnn_hidden\", default=\"128,128\")\n",
        "    P.add_argument(\"--resnet_hidden\", default=\"128,128\")\n",
        "    P.add_argument(\"--icnn_hidden\", default=\"128,128\")\n",
        "    # learning rates\n",
        "    P.add_argument(\"--mlp_lr\", type=float)\n",
        "    P.add_argument(\"--mlp_icnn_lr\", type=float)\n",
        "    P.add_argument(\"--resnet_lr\", type=float)\n",
        "    P.add_argument(\"--icnn_lr\", type=float)\n",
        "    # activations\n",
        "    P.add_argument(\"--mlp_act\", default=\"relu\")\n",
        "    P.add_argument(\"--mlp_icnn_act\", default=\"softplus\")\n",
        "    P.add_argument(\"--resnet_act\", default=\"relu\")\n",
        "    P.add_argument(\"--icnn_act\", default=\"softplus\")\n",
        "    return P\n",
        "\n",
        "def main(argv=None):\n",
        "    args, _ = build_parser().parse_known_args(argv or sys.argv[1:])\n",
        "    base_lr = args.lr\n",
        "    models = {\n",
        "        \"MLP\": {\n",
        "            \"make\": lambda: MLP(parse_hidden(args.mlp_hidden),\n",
        "                                act=_act(args.mlp_act)),\n",
        "            \"lr\": args.mlp_lr or base_lr},\n",
        "        \"MLP_ICNN\": {\n",
        "            \"make\": lambda: MLP_ICNN(parse_hidden(args.mlp_icnn_hidden),\n",
        "                                     act=_act(args.mlp_icnn_act)),\n",
        "            \"lr\": args.mlp_icnn_lr or base_lr*3},\n",
        "        \"ResNet\": {\n",
        "            \"make\": lambda: ResNet(parse_hidden(args.resnet_hidden),\n",
        "                                   act=_act(args.resnet_act)),\n",
        "            \"lr\": args.resnet_lr or base_lr},\n",
        "        \"ICNN\": {\n",
        "            \"make\": lambda: ICNN(parse_hidden(args.icnn_hidden),\n",
        "                                 act=_act(args.icnn_act)),\n",
        "            \"lr\": args.icnn_lr or base_lr*3},\n",
        "    }\n",
        "\n",
        "    all_res = {}\n",
        "    for fn in FUNCTIONS:\n",
        "        print(\"\\n\" + \"=\"*78 + f\"\\n{FUNCPRINT[fn]} benchmark\\n\" + \"=\"*78)\n",
        "        all_res[fn] = []\n",
        "        for d in args.dims:\n",
        "            rows = bench(fn, d, args.steps, args.patience,\n",
        "                         models, args.runs, args.batch, args.verbose)\n",
        "            all_res[fn].extend(rows)\n",
        "            for r in rows:\n",
        "                print(f\"{r['model']:<10}\"\n",
        "                      f\"L2impl {r['l2I']:.2e}  L2dir {r['l2E']:.2e}  \"\n",
        "                      f\"time {r['tI']:.1f}/{r['tE']:.1f}s  \"\n",
        "                      f\"ρ {r['rho_mu']:.2f} σ={r['rho_sigma']:.2f}\")\n",
        "\n",
        "    tex_tables(all_res, args.dims)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI01Pb0i97Qq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNZ9n+ZOvwYO0Q5Az8KHWwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}